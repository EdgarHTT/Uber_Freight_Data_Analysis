{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8fda2d-fb2b-445a-994b-0dbf1e54a987",
   "metadata": {},
   "source": [
    "# Data analytics assesment Case\n",
    "## 1. Identifying The Problem\n",
    "As part of skills assessment for uber freight i was given a data analytics problem and a data set. The given data is on a route level and its expected to be transformed from one format to another. An example was given. For this report i'll be using Pandas and Numpy just to manipulate data within this notebook, later i'll refine the approach to the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7664dd-f00d-46de-a0e8-9aebc7287bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbe4dd8-f1c3-4e03-9eee-b4bf00f94f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.read_excel(\n",
    "    'Uber Freight_Data Analytics_Assessment 2024.xlsx',\n",
    "    sheet_name='Example',\n",
    "    usecols=range(1,16),\n",
    "    header=2)\n",
    "inputFormat = ex.loc[[0,1,2]].drop('Unnamed: 15', axis=1)\n",
    "outputFormat = ex.loc[[7,8,9]]\n",
    "outputFormat.columns = ex.loc[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876fa003-a960-4ffa-af33-4272fe54b2fd",
   "metadata": {},
   "source": [
    "### Example:\n",
    "F053978 is one **truckload route outbound**. All loads are picked up in Harrisburg.\n",
    "When the truck leaves Harrisburg, there are **35,760 pounds** in the truck. The first\n",
    "delivery is in Barronett (sequence=1). After the truckload leaves from Barronett,\n",
    "there are **35,666 pounds** in the truckload. Next delivery is Hillsboro where the\n",
    "truckload leaves with **122 pounds**. Those final pounds will be dropped in the last\n",
    "delivery: San Geronimo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48425f0d-2950-4a9e-9a84-b886ebb599e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROUTE ID</th>\n",
       "      <th>SEQ</th>\n",
       "      <th>DATE</th>\n",
       "      <th>MODE</th>\n",
       "      <th>LOAD ID</th>\n",
       "      <th>FLOW TYPE</th>\n",
       "      <th>FROM CITY</th>\n",
       "      <th>FROM ST</th>\n",
       "      <th>FROM ZIP</th>\n",
       "      <th>TO CITY</th>\n",
       "      <th>TO STATE</th>\n",
       "      <th>TO ZIP</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>LEG WEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F053978</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>TL</td>\n",
       "      <td>153991</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>PA</td>\n",
       "      <td>17109</td>\n",
       "      <td>Barronett</td>\n",
       "      <td>WI</td>\n",
       "      <td>54813</td>\n",
       "      <td>Harrisburg -&gt; Barronett</td>\n",
       "      <td>35760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F053978</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>TL</td>\n",
       "      <td>27145</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>Barronett</td>\n",
       "      <td>WI</td>\n",
       "      <td>54813</td>\n",
       "      <td>Hillsboro</td>\n",
       "      <td>OR</td>\n",
       "      <td>97124</td>\n",
       "      <td>Barronett -&gt; Hillsboro</td>\n",
       "      <td>35666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F053978</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>TL</td>\n",
       "      <td>215065</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>Hillsboro</td>\n",
       "      <td>OR</td>\n",
       "      <td>97124</td>\n",
       "      <td>San Geronimo</td>\n",
       "      <td>CA</td>\n",
       "      <td>94963</td>\n",
       "      <td>Hillsboro -&gt; San Geronimo</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ROUTE ID SEQ                 DATE MODE LOAD ID FLOW TYPE   FROM CITY  \\\n",
       "0  F053978   1  2019-01-01 00:00:00   TL  153991  Outbound  Harrisburg   \n",
       "1  F053978   2  2019-01-01 00:00:00   TL   27145  Outbound   Barronett   \n",
       "2  F053978   3  2019-01-01 00:00:00   TL  215065  Outbound   Hillsboro   \n",
       "\n",
       "  FROM ST FROM ZIP       TO CITY TO STATE TO ZIP                DESCRIPTION  \\\n",
       "0      PA    17109     Barronett       WI  54813    Harrisburg -> Barronett   \n",
       "1      WI    54813     Hillsboro       OR  97124     Barronett -> Hillsboro   \n",
       "2      OR    97124  San Geronimo       CA  94963  Hillsboro -> San Geronimo   \n",
       "\n",
       "  LEG WEIGHT  \n",
       "0      35760  \n",
       "1      35666  \n",
       "2        122  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputFormat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23143b37-47bd-422a-a5b5-59926207f642",
   "metadata": {},
   "source": [
    "Load 153991 has **94 pounds**, which are picked in Harrisburg and delivered in\n",
    "Barronett. As it is the **first drop** in the route, it was **picked up last**. Load 27145 has\n",
    "**35,544 pounds**, which are picked up in Harrisburg and delivered in Hillsboro. Load\n",
    "215065 has **122 pounds**, which are picked up in Harrisburg and delivered in San\n",
    "Geronimo. It was picked up first as it was going to be delivered last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e367904-ac0e-4d82-91e3-4769215f9e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>6</th>\n",
       "      <th>LOAD ID</th>\n",
       "      <th>LOAD MODE</th>\n",
       "      <th>ROUTE ID</th>\n",
       "      <th>FLOW TYPE</th>\n",
       "      <th>PICKUP</th>\n",
       "      <th>DROPOFF</th>\n",
       "      <th>ORIGIN CITY</th>\n",
       "      <th>ORIGIN STATE</th>\n",
       "      <th>ORIGIN ZIP</th>\n",
       "      <th>DEST CITY</th>\n",
       "      <th>DEST STATE</th>\n",
       "      <th>DEST ZIP</th>\n",
       "      <th>EARLIESTPICKTIME</th>\n",
       "      <th>LATESTPICKTIME</th>\n",
       "      <th>LOAD WEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>153991</td>\n",
       "      <td>LTL</td>\n",
       "      <td>F053978</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>PA</td>\n",
       "      <td>17109</td>\n",
       "      <td>Barronett</td>\n",
       "      <td>WI</td>\n",
       "      <td>54813</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27145</td>\n",
       "      <td>TL</td>\n",
       "      <td>F053978</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>PA</td>\n",
       "      <td>17109</td>\n",
       "      <td>Hillsboro</td>\n",
       "      <td>OR</td>\n",
       "      <td>97124</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>35544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>215065</td>\n",
       "      <td>LTL</td>\n",
       "      <td>F053978</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>PA</td>\n",
       "      <td>17109</td>\n",
       "      <td>San Geronimo</td>\n",
       "      <td>CA</td>\n",
       "      <td>94963</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "6 LOAD ID LOAD MODE ROUTE ID FLOW TYPE PICKUP DROPOFF ORIGIN CITY  \\\n",
       "7  153991       LTL  F053978  Outbound      3       4  Harrisburg   \n",
       "8   27145        TL  F053978  Outbound      2       5  Harrisburg   \n",
       "9  215065       LTL  F053978  Outbound      1       6  Harrisburg   \n",
       "\n",
       "6 ORIGIN STATE ORIGIN ZIP     DEST CITY DEST STATE DEST ZIP  \\\n",
       "7           PA      17109     Barronett         WI    54813   \n",
       "8           PA      17109     Hillsboro         OR    97124   \n",
       "9           PA      17109  San Geronimo         CA    94963   \n",
       "\n",
       "6     EARLIESTPICKTIME       LATESTPICKTIME LOAD WEIGHT  \n",
       "7  2019-01-01 00:00:00  2019-01-01 00:00:00          94  \n",
       "8  2019-01-01 00:00:00  2019-01-01 00:00:00       35544  \n",
       "9  2019-01-01 00:00:00  2019-01-01 00:00:00         122  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputFormat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0461dcc-3293-499e-a3da-ab05c0cccf5b",
   "metadata": {},
   "source": [
    "## 2. Research and Refining  \n",
    "### Defining the Context:\n",
    "\n",
    "### Assumptions:\n",
    "* 0 lb < LTL (Less Than Truckload) <= 20,000 lb\n",
    "* 20,000 lb < TL (TruckLoad) <= 45,000 lb\n",
    "* LTL Avg 300 mi/day\n",
    "\n",
    "### Questions to answer:\n",
    "#### **1. What is the difference within an inbound route and an outbound route?**\n",
    "\n",
    " 1. **Inbound Logistics (Inbound Routes)**\n",
    "    * **Definition:** The movement of **raw materials, components, or finished goods into** a facility from suppliers, manufacturers, or vendors.\n",
    "    * **Focus:**\n",
    "      * Receiving goods.\n",
    "      * Managing supplier relationships.\n",
    "      * Optimizing transportation costs and lead times.\n",
    "    * **Key Activities:**\n",
    "      * Procurement (sourcing materials).\n",
    "      * Transportation from suppliers to warehouses/factories.\n",
    "      * Inventory management (staging raw materials for production).\n",
    "      * Quality checks upon receipt.\n",
    "    * **Example:**\n",
    "      * A car factory receives steel, tires, and electronics from suppliers via inbound routes.\n",
    "      * A retailer’s warehouse receives inventory from manufacturers.\n",
    "\n",
    " 2. **Outbound Logistics (Outbound Routes)**\n",
    "  \n",
    "    * **Definition:** The movement of **finished goods out of** a facility to customers, distributors, or retailers.\n",
    "    * **Focus:**\n",
    "      * Delivering products to end-users.\n",
    "      * Ensuring timely, cost-effective distribution.\n",
    "      * Managing customer satisfaction.\n",
    "    * **Key Activities:**\n",
    "      * Order fulfillment (picking, packing, shipping).\n",
    "      * Last-mile delivery to customers.\n",
    "      * Managing carriers (trucks, ships, planes).\n",
    "      * Reverse logistics (returns).\n",
    "    * **Example:**\n",
    "      * An e-commerce warehouse ships orders to customers via outbound routes.\n",
    "      * A beverage distributor delivers products to grocery stores.\n",
    "3. **Key Differences**\n",
    "\n",
    "| Aspect | \tInbound Logistics | Outbound Logistics |\n",
    "|---|---|---|  \n",
    "|Direction | Suppliers → Facility | Facility → Customers/Retailers |\n",
    "|Stakeholders | Suppliers, procurement teams | Customers, retailers, delivery partners|\n",
    "|Primary Goal | Ensure materials arrive on time and in full | Ensure products reach customers efficiently |\n",
    "| Cost Focus | Minimize procurement/transportation costs | Optimize delivery speed and customer service |\n",
    "| Challenges | Supplier delays, quality control | Last-mile delivery, returns management |\n",
    "  \n",
    "   4. **Integration in Supply Chain**\n",
    "\n",
    "       * **Inbound** ensures raw materials are available for production.\n",
    "       * **Outbound** ensures finished products reach markets or consumers.\n",
    "       * Both require coordination with **transportation management systems (TMS)** and **warehouse management systems (WMS).**\n",
    "  \n",
    "   5. **Real-World Example**\n",
    "  \n",
    "      * **Inbound:** A Walmart distribution center receives pallets of goods from Procter & Gamble.\n",
    "      * **Outbound:** The same center ships those goods to Walmart stores or directly to online customers.\n",
    "\n",
    " * **Why It Matters**\n",
    "\n",
    "   * **Inbound efficiency** reduces production downtime and inventory costs.\n",
    "   * **Outbound efficiency** boosts customer satisfaction and brand reputation.\n",
    "   * Poor inbound logistics can disrupt production; poor outbound logistics can lead to lost sales.\n",
    "    \n",
    "#### **2. What is the difference within an LTL and a TL load?**\n",
    "\n",
    "In logistics and trucking, **LTL (Less Than Truckload)** and **TL (Truckload)** refer to two distinct modes of freight transportation based on shipment size and how space in a truck is utilized. Here’s a breakdown of their differences:\n",
    " \n",
    " **1. Definitions**\n",
    " * **LTL (Less Than Truckload):**\n",
    "           * Shipments that do not require the full space or weight capacity of a truck.\n",
    "           * Multiple customers share the same trailer, with each paying for the portion of space their freight occupies.\n",
    "           * Ideal for smaller shipments (typically **under 10,000 lbs** or **6–12 pallets**).\n",
    " * **TL (Truckload):**\n",
    "            * Shipments large enough to occupy an entire trailer (or close to it).\n",
    "            * A single customer’s freight fills the truck, and no other cargo is added.\n",
    "            * Ideal for large shipments (typically over **10,000 lbs** or **10+ pallets**).\n",
    "\n",
    " **2. Key Differences**\n",
    "|**Aspect** | **LTL** | **TL** |\n",
    "|---|---|---|\n",
    "|**Shipment Size** | Smaller (partial trailer space) | Large (full trailer) |\n",
    "|**Cost Structure** | Paid per \"space used\" + freight class | Flat rate for the entire trailer |\n",
    "|**Transit Time** | Longer (due to multiple stops for consolidation/deconsolidation) | Faster (direct point-to-point delivery) |\n",
    "|**Handling** | More handling (transferred between hubs) | Minimal handling (sealed at origin)|\n",
    "|**Risk of Damage**| Higher (multiple stops and transfers) | Lower (single load, no transfers)|\n",
    "|**Pricing Factors**| Weight, dimensions, freight class, zones | Distance, fuel, trailer type |\n",
    "|**Best For** | Small businesses, partial loads, cost-sensitive shipments | Large businesses, urgent/priority shipments, high-value goods|\n",
    "\n",
    "  **3. When to Use LTL vs. TL**\n",
    "* **LTL is better if:**\n",
    "  * Your shipment is **small** (e.g., 1–6 pallets).\n",
    "  * You want to **save costs** by sharing trailer space.\n",
    "  * Delivery speed is flexible (e.g., non-urgent goods).\n",
    "  * You need access to **freight class discounts** (e.g., for lighter, non-dense items).\n",
    "\n",
    "* **TL is better if:**\n",
    "  * Your shipment **fills most/all of a trailer.**\n",
    "  * You need **faster, guaranteed transit times** (e.g., perishable goods).\n",
    "  * Your cargo is **high-value or fragile** (minimizes handling risk).\n",
    "  * You require specialized equipment (e.g., refrigerated trailers, flatbeds).\n",
    "\n",
    " **4. Practical Examples**\n",
    "* **LTL:**\n",
    "    * A small business ships 4 pallets of clothing from Los Angeles to Chicago.\n",
    "    * A manufacturer sends spare parts to a repair facility.\n",
    "* **TL:**\n",
    "    * A furniture company ships 22 pallets of sofas from a warehouse to a retail store.\n",
    "    * A food distributor transports a full load of frozen goods in a refrigerated trailer.\n",
    "\n",
    " **5. Pros and Cons**\n",
    "|**Mode** |**Pros**|**Cons**|\n",
    "|---|---|---|\n",
    "|**LTL** | Cost-effective for small loads, flexible | Slower, higher risk of damage, complex pricing |\n",
    "|**TL** | Faster, secure, simplified logistics | Expensive for small shipments |\n",
    "\n",
    " **6. TL vs. LTL in Special Cases**\n",
    " * **Dimensional Weight:** LTL pricing often uses dimensional weight (size vs. actual weight), while TL focuses on actual weight.\n",
    " * **Freight Class:** LTL requires assigning a freight class (based on density, stowability, etc.), whereas TL does not.\n",
    " * **Accessorials:** LTL may charge extra for liftgates, inside delivery, or residential pickup; TL fees are simpler.\n",
    "\n",
    "**Which to Choose?**\n",
    "* **Rule of Thumb:** If your shipment uses **>75% of a trailer’s space/weight**, TL is more efficient. For smaller loads, LTL saves money.\n",
    "* **Hybrid Option:** Some carriers offer **Partial Truckload (PTL)**, which bridges the gap between LTL and TL for mid-sized shipments.\n",
    "\n",
    "\n",
    "### My own questions\n",
    "1. Why are load modes all TL in the input data even when they dont meet the criteria?\n",
    "   * Since data given is on a route level, all the routes are grouped together meaning that every consolidated route is a truckload. Once the routes are divided, they are calculated to their real mode of transportation.\n",
    "3. How does delivery sequence translates to load and unload in output?\n",
    "   * Delivery sequences seems to correspond to a stack structure where the last shipment to be loaded is the first to be delivered. This may be due to how loading and unloading freigths works.\n",
    "4. How does dates affect earliest pickup times and latest pick times?\n",
    "   * Due to the inbound flow type, the truck is picking up loads by the sequence shown, assuming a truck drives on average 300 miles per day, earliest and latest pickup times can vary.\n",
    "\n",
    "#### I asked some questions to the AI to explain more in depth about routes consolidation and shipments\n",
    "  \n",
    "### **Outbound Shipments in a Consolidated Route**\n",
    "\n",
    "* **Earliest Pick Date:**\n",
    "    * For outbound consolidated shipments (e.g., multiple orders grouped into one truckload), the **earliest possible pick date** is determined by the **latest order** in the batch.\n",
    "    * Example: If three orders are consolidated, and the earliest order is ready on Monday, but the last order isn’t ready until Wednesday, the **actual pick date** for the entire consolidated load is Wednesday.\n",
    "    * **Why?** You can’t ship until all orders in the consolidation are ready. The \"earliest\" possible date is constrained by the slowest order.\n",
    "\n",
    "* **Scheduling Logic:**\n",
    "    * All shipments in the consolidated route share the **same pick date**, which is set to the **latest** \"ready\" date of the grouped orders.\n",
    "    * Flexibility: If some orders are ready earlier, they must wait in the facility until the consolidated load is finalized.\n",
    "\n",
    "#### **Inbound Shipments in a Consolidated Route**\n",
    "\n",
    "* **Pick Date Variability:**\n",
    "    * Inbound consolidated routes involve collecting goods from **multiple suppliers** (e.g., milk runs). Here, the **earliest and latest pick dates** depend on:\n",
    "        1. **Supplier availability** (when goods are ready).\n",
    "        2. **Transit time** between suppliers.\n",
    "        3. **Carrier scheduling** (e.g., grouping pickups geographically).\n",
    "    * Example: A truck might pick up from Supplier A (earliest: Monday), then Supplier B (earliest: Tuesday), and Supplier C (earliest: Wednesday). The **latest pick date** for the entire inbound route would be Wednesday.\n",
    "\n",
    "* **Scheduling Logic:**\n",
    "    * The carrier must coordinate a route that accommodates all suppliers’ timelines.\n",
    "    * The **earliest pick date** is the first available pickup time (e.g., Monday), but the **latest pick date** is determined by the last supplier’s availability or transit time between stops.\n",
    "\n",
    "#### **Key Differences in Consolidated Routes**\n",
    "| **Aspect** | **Outbound Consolidation** | **Inbound Consolidation** |\n",
    "|---|---|---|\n",
    "| **Pick Date Driver** | Determined by the **slowest/latest order** in the batch. | Determined by **supplier availability** and **route efficiency.** |\n",
    "| **Flexibility** | Facility controls when orders are staged (but must wait for the slowest). | Carrier must adapt to external supplier schedules. |\n",
    "| **Complexity** | Internally managed (within your facility). | Externally constrained (dependent on suppliers). |\n",
    "| **Example** | Waiting for 3 customer orders to be packed before a truck can depart. |\tA truck visiting 5 suppliers across a region, each with their own ready times.|\n",
    "\n",
    "#### **Why This Matters**\n",
    "1. **Outbound:** Efficiency hinges on synchronizing internal workflows to avoid delays (e.g., ensuring all orders in a consolidated load are ready simultaneously).\n",
    "2. **Inbound:** Requires negotiating with suppliers to align their timelines and minimize idle time in the carrier’s route.\n",
    "\n",
    "#### **Special Case: Cross-Docking**\n",
    "\n",
    "In cross-docking, inbound and outbound pick dates may overlap. For example:\n",
    "* Inbound goods from suppliers are unloaded and immediately reloaded onto outbound trucks.\n",
    "* Both inbound and outbound pick dates must align perfectly, requiring tight coordination.\n",
    "\n",
    "#### **TL;DR**\n",
    "* **Outbound:** All shipments in a consolidated route share the **same pick date**, dictated by the **last order’s readiness.**\n",
    "* **Inbound:** Pick dates vary by supplier, and the route’s **earliest/latest pick dates** depend on supplier availability and transit time between stops.\n",
    "\n",
    "This distinction is critical for avoiding delays and optimizing costs in complex supply chains!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d695a8b-8291-4425-b5b9-d26291947e41",
   "metadata": {},
   "source": [
    "### Researching solutions \n",
    "#### Load inputData\n",
    "```Python\n",
    "inputData = pd.read_excel(\n",
    "    'Uber Freight_Data Analytics_Assessment 2024.xlsx',\n",
    "    sheet_name='Input Data',\n",
    "    usecols=range(0,14),\n",
    "    header=0)\n",
    "inputData.sort_values(by='ROUTE ID','SEQ')\n",
    "```\n",
    "\n",
    "#### Calculating rough estimate of earliest pickup time\n",
    "* Cordinates of each city provided by the first part of the assigment can be used to calculate geodesic distance between two places using GeoPy library\n",
    "* With the rough estimate we can calculate earliest pick up time between each stop\n",
    "* I should check if all the cities are present for the distance calculations\n",
    "\n",
    "```Python\n",
    "from geopy.distance import geodesic\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807b72d-b162-44d0-be80-032594e04e86",
   "metadata": {},
   "source": [
    "Refining solution/PseudoCode\n",
    " Breaking up the problem into smaller subproblems\n",
    " 1. Transform InputData format into OutputData format\n",
    "      1. Import Input data\n",
    "      2. Obtain every Route ID\n",
    "      3. Obtain Cities coordinates\n",
    "      4. Obtain Output data headers\n",
    "      5. Loop through every Route\n",
    "      6. Calculate each column\n",
    "         * outLoadId = inLoadId\n",
    "         * if loadWeigth > 20,000:\n",
    "               loadMode = \"TL\"\n",
    "           else:\n",
    "               loadMode = \"LTL\"\n",
    "         * routeId = routeId\n",
    "         * Pickup = range(maxSeq,0,-1)[seq - 1]\n",
    "         * Dropoff = maxSeq + seq\n",
    "         * originCity = inputData[inputData['ROUTE ID'] == routeId and inputData['SEQ'] == 1].loc['FROM CITY']\n",
    "         * originState = inputData[inputData['ROUTE ID'] == routeId and inputData['SEQ'] == 1].loc['FROM ST']\n",
    "         * originZip = inputData[inputData['ROUTE ID'] == routeId and inputData['SEQ'] == 1].loc['FROM ZIP']\n",
    "         * destCity = \"TO CITY\"\n",
    "         * destState = \"TO STATE\"\n",
    "         * destZip = \"TO ZIP\"\n",
    "         * earliestPick\n",
    "         * if geoDist > 300miles:\n",
    "               earliestPick = seq1Date + (geoDist // 300)\n",
    "         * lastestPick = 'DATE'\n",
    "         * loadWeight = loadweightsList[seq]\n",
    "         * for n in range(len(inputData['LEG WEIGHT']) - 1):\n",
    "               remind -= legWeight[n + 1]\n",
    "               loadWeightsList[n] = remind\n",
    "               loadWeightsList[-1] = remind\n",
    "      7. Assign each value\n",
    "      8. Testing\n",
    "      9. Import Data to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b636f72c-cfa4-4b8b-91b5-d004c22ad145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRefining solution/PseudoCode\\n Breaking up the problem into smaller subproblems\\n 1. Transform InputData format into OutputData format\\n      1. Import Input data\\n      2. Obtain every Route ID\\n      3. Obtain Cities coordinates\\n      4. Obtain Output data headers\\n      5. Loop through every Route\\n      6. Calculate each column\\n         * outLoadId = inLoadId\\n         * if loadWeigth > 20,000:\\n               loadMode = \"TL\"\\n           else:\\n               loadMode = \"LTL\"\\n         * routeId = routeId\\n         * Pickup = range(maxSeq,0,-1)[seq - 1]\\n         * Dropoff = maxSeq + seq\\n         * originCity = inputData[inputData[\\'ROUTE ID\\'] == routeId and inputData[\\'SEQ\\'] == 1].loc[\\'FROM CITY\\']\\n         * originState = inputData[inputData[\\'ROUTE ID\\'] == routeId and inputData[\\'SEQ\\'] == 1].loc[\\'FROM ST\\']\\n         * originZip = inputData[inputData[\\'ROUTE ID\\'] == routeId and inputData[\\'SEQ\\'] == 1].loc[\\'FROM ZIP\\']\\n         * destCity = \"TO CITY\"\\n         * destState = \"TO STATE\"\\n         * destZip = \"TO ZIP\"\\n         * earliestPick\\n         * if geoDist > 300miles:\\n               earliestPick = seq1Date + (geoDist // 300)\\n         * lastestPick = \\'DATE\\'\\n         * loadWeight = loadweightsList[seq]\\n         * for n in range(len(inputData[\\'LEG WEIGHT\\']) - 1):\\n               remind -= legWeight[n + 1]\\n               loadWeightsList[n] = remind\\n               loadWeightsList[-1] = remind\\n      7. Assign each value\\n      8. Testing\\n      9. Import Data to excel\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Refining solution/PseudoCode\n",
    " Breaking up the problem into smaller subproblems\n",
    " 1. Transform InputData format into OutputData format\n",
    "      1. Import Input data\n",
    "      2. Obtain every Route ID\n",
    "      3. Obtain Cities coordinates\n",
    "      4. Obtain Output data headers\n",
    "      5. Loop through every Route\n",
    "      6. Calculate each column\n",
    "         * outLoadId = inLoadId\n",
    "         * if loadWeigth > 20,000:\n",
    "               loadMode = \"TL\"\n",
    "           else:\n",
    "               loadMode = \"LTL\"\n",
    "         * routeId = routeId\n",
    "         * Pickup = range(maxSeq,0,-1)[seq - 1]\n",
    "         * Dropoff = maxSeq + seq\n",
    "         * originCity = inputData[inputData['ROUTE ID'] == routeId and inputData['SEQ'] == 1].loc['FROM CITY']\n",
    "         * originState = inputData[inputData['ROUTE ID'] == routeId and inputData['SEQ'] == 1].loc['FROM ST']\n",
    "         * originZip = inputData[inputData['ROUTE ID'] == routeId and inputData['SEQ'] == 1].loc['FROM ZIP']\n",
    "         * destCity = \"TO CITY\"\n",
    "         * destState = \"TO STATE\"\n",
    "         * destZip = \"TO ZIP\"\n",
    "         * earliestPick\n",
    "         * if geoDist > 300miles:\n",
    "               earliestPick = seq1Date + (geoDist // 300)\n",
    "         * lastestPick = 'DATE'\n",
    "         * loadWeight = loadweightsList[seq]\n",
    "         * for n in range(len(inputData['LEG WEIGHT']) - 1):\n",
    "               remind -= legWeight[n + 1]\n",
    "               loadWeightsList[n] = remind\n",
    "               loadWeightsList[-1] = remind\n",
    "      7. Assign each value\n",
    "      8. Testing\n",
    "      9. Import Data to excel\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2863d9f2-b566-445d-b918-3b0ee501e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading inputData\n",
    "inputData = pd.read_excel(\n",
    "    'Uber Freight_Data Analytics_Assessment 2024.xlsx',\n",
    "    sheet_name='Input Data',\n",
    "    usecols=range(0,14),\n",
    "    header=0)\n",
    "inputData.sort_values(by=['ROUTE ID','SEQ'])\n",
    "\n",
    "# Initializing outputData dataframe\n",
    "outputData = pd.read_excel(\n",
    "    'Uber Freight_Data Analytics_Assessment 2024.xlsx',\n",
    "    sheet_name='Output template',\n",
    "    usecols=range(0,15))\n",
    "\n",
    "\"\"\"\n",
    "I decided that importing a bigger database is a better aproach since USA has more than 10,000 cities\n",
    "still, 140 cities from the inputData were missing from the imported database\n",
    "\"\"\"\n",
    "# Cities Coordinates\n",
    "citiesCoor = pd.read_excel(\n",
    "    'Uber Freight Engineering - Customer Demands Business Case.xlsx',\n",
    "    sheet_name='Data',\n",
    "    usecols=[1,2,4,5],\n",
    "    header=0)\n",
    "\n",
    "# Checking for missing cities\n",
    "inputCities = set(inputData['FROM CITY']) | set(inputData['TO CITY'])\n",
    "# inputCities 971\n",
    "# citiesCoor 370\n",
    "\n",
    "# cities coordinates and inputData Cities are different\n",
    "missingCities = set([name.upper() for name in inputCities]) - set(citiesCoor['CUSTOMER CITY'])\n",
    "\n",
    "# missingCities 905\n",
    "\n",
    "# Importing cities from US cities database\n",
    "uscities = pd.read_csv('uscities.csv', usecols = [0,2,6,7])\n",
    "\n",
    "# Making set of all found cities\n",
    "foundCities = inputCities & set(uscities['city'])\n",
    "# Cities not found in the database totals 140\n",
    "\n",
    "# Adding coordinates\n",
    "mask = uscities['city'].isin(foundCities)\n",
    "cities = uscities[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f9d48da-809e-4510-88b3-f88de786af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "from datetime import timedelta\n",
    "\n",
    "#Assuming LTL carriers cover 300mi/day\n",
    "AVGMILEAGE = 300\n",
    "\n",
    "\n",
    "def loadWeight(index):\n",
    "    \"\"\"\n",
    "    Calculates the load weight of each trip.\n",
    "\n",
    "    Uses index of input dataframe.\n",
    "    \"\"\"\n",
    "    route = inputData.loc[index]['ROUTE ID']\n",
    "    flow = inputData.loc[index]['FLOW TYPE']\n",
    "    seq = inputData.loc[index]['SEQ']\n",
    "    seqList = list(inputData['SEQ'].loc[inputData['ROUTE ID'] == route])\n",
    "\n",
    "\n",
    "    if flow == 'Outbound':\n",
    "        if seq == len(seqList):\n",
    "            return inputData.loc[index]['LEG WEIGHT']\n",
    "        nextWeight = inputData.loc[(inputData['ROUTE ID'] == route ) & (inputData['SEQ'] == seq + 1)]['LEG WEIGHT']\n",
    "        nextWeight = nextWeight.iloc[0]\n",
    "\n",
    "        return inputData.loc[index]['LEG WEIGHT'] - nextWeight\n",
    "        \n",
    "    else:\n",
    "        if seq == 1:\n",
    "            return inputData.loc[index]['LEG WEIGHT']\n",
    "        prevWeight = inputData.loc[(inputData['ROUTE ID'] == route ) & (inputData['SEQ'] == seq - 1)]['LEG WEIGHT']\n",
    "        prevWeight = prevWeight.iloc[0]\n",
    "\n",
    "        return inputData.loc[index]['LEG WEIGHT'] - prevWeight\n",
    "\n",
    "def pickDrop(index):\n",
    "    \"\"\"\n",
    "    Determines de pickup and dropoff of each trip.\n",
    "    \"\"\"\n",
    "    route = inputData.loc[index]['ROUTE ID']\n",
    "    flow = inputData.loc[index]['FLOW TYPE']\n",
    "    seq = inputData.loc[index]['SEQ']\n",
    "    seqList = list(inputData['SEQ'].loc[inputData['ROUTE ID'] == route])\n",
    "    seqList.sort()\n",
    "\n",
    "    if flow == 'Outbound':\n",
    "        pickup = seqList[len(seqList) - seq]\n",
    "        dropoff = seq + max(seqList)\n",
    "    else:\n",
    "        pickup = seq\n",
    "        dropoff = seqList[len(seqList) - seq] + max(seqList)\n",
    "\n",
    "    return pickup, dropoff\n",
    "\n",
    "    \n",
    "\n",
    "def dates(index):\n",
    "    \"\"\"\n",
    "    Determines and calculates the earliest and latest pickup dates.\n",
    "    Uses geodesic calculations to determine a rough estimate distance for each stop,\n",
    "    \n",
    "    In Inbound routes the earliest pickup depends on the supplier, \n",
    "    and the latest on the calculated time of arrival\n",
    "\n",
    "    In Outbound routes the earliest and latest pickup depends on the last load in the sequence.\n",
    "    \"\"\"\n",
    "    route = inputData.loc[index]['ROUTE ID']\n",
    "    flow = inputData.loc[index]['FLOW TYPE']\n",
    "    seq = inputData.loc[index]['SEQ']\n",
    "    seqList = list(inputData['SEQ'].loc[inputData['ROUTE ID'] == route])\n",
    "    seqList.sort()\n",
    "\n",
    "    if flow == 'Outbound':\n",
    "        eDate = inputData.loc[(inputData['ROUTE ID'] == route ) & (inputData['SEQ'] == seqList[-1])]['DATE'].iloc[0]\n",
    "        lDate = eDate\n",
    "\n",
    "        return eDate, lDate\n",
    "    else:\n",
    "        eDate = inputData.loc[(inputData['ROUTE ID'] == route ) & (inputData['SEQ'] == seq)]['DATE'].iloc[0]\n",
    "        \n",
    "        fromCity = inputData.iloc[index]['FROM CITY']\n",
    "        fromSt = inputData.iloc[index]['FROM ST']\n",
    "        toCity = inputData.iloc[index]['TO CITY']\n",
    "        toSt = inputData.iloc[index]['TO STATE']\n",
    "\n",
    "        # Checks that the origin and destination cities exists whitin the data base to perform the calculations\n",
    "        check1 = cities[(cities['city'] == fromCity) & (cities['state_id'] == fromSt)].any()\n",
    "        check2 = cities[(cities['city'] == toCity) & (cities['state_id'] == toSt)].any()\n",
    "\n",
    "        \n",
    "        if check1.any() and check2.any():\n",
    "            fromCityData = cities.loc[(cities['city'] == fromCity) & (cities['state_id'] == fromSt)]\n",
    "            toCityData = cities.loc[(cities['city'] == toCity) & (cities['state_id'] == toSt)]\n",
    "\n",
    "            \n",
    "            # Geodesic calculation since it takes into account earth curvature\n",
    "            estDist = geodesic((fromCityData['lat'].item(),fromCityData['lng'].item()),\n",
    "                               (toCityData['lat'].item(),toCityData['lng'].item())).mi\n",
    "                \n",
    "            sumDays = int(estDist // AVGMILEAGE)\n",
    "\n",
    "            lDate = eDate + timedelta(days=sumDays)\n",
    "            \n",
    "            return eDate, lDate\n",
    "\n",
    "        #If the cities wheren't found, it defaults into the original earliest Pickup\n",
    "        lDate = eDate\n",
    "\n",
    "        # Storing cities not found\n",
    "        if check1.any():\n",
    "            citiesNt.append((fromCity,fromSt))\n",
    "        if check2.any():\n",
    "            citiesNt.append((toCity,toSt))\n",
    "        \n",
    "        return eDate, lDate\n",
    "        \n",
    "# Lists initialization\n",
    "# whole List assigments are faster than dataframe row iterations\n",
    "loadWeightLs = []\n",
    "loadModeLs = []\n",
    "pickup = []\n",
    "dropoff = []\n",
    "originCity = []\n",
    "originState = []\n",
    "originZip = []\n",
    "destCity = []\n",
    "destState = []\n",
    "destZip = []\n",
    "earliestDateLs = []\n",
    "latestDateLs = []\n",
    "\n",
    "#Cities not found\n",
    "citiesNt = []\n",
    "\n",
    "for index, row in inputData.iterrows():\n",
    "\n",
    "    #Load weight\n",
    "    loadWeightLs.append(loadWeight(index))\n",
    "\n",
    "    # Loadmode\n",
    "    if loadWeightLs[index] > 20000:\n",
    "        loadModeLs.append('TL')\n",
    "    else:\n",
    "        loadModeLs.append('LTL')\n",
    "\n",
    "    #Pick and Drop sequence\n",
    "    pick, drop = pickDrop(index)\n",
    "    pickup.append(pick)\n",
    "    dropoff.append(drop)\n",
    "\n",
    "    # Origin city\n",
    "    if row['FLOW TYPE'] == 'Outbound':\n",
    "        originCity.append(inputData.loc[(inputData['ROUTE ID'] == row['ROUTE ID']) & (inputData['SEQ'] == 1)]['FROM CITY'].iloc[0])\n",
    "        originState.append(inputData.loc[(inputData['ROUTE ID'] == row['ROUTE ID']) & (inputData['SEQ'] == 1)]['FROM ST'].iloc[0])\n",
    "        originZip.append(inputData.loc[(inputData['ROUTE ID'] == row['ROUTE ID']) & (inputData['SEQ'] == 1)]['FROM ZIP'].iloc[0])\n",
    "    else:\n",
    "        seqList = list(inputData['SEQ'].loc[inputData['ROUTE ID'] == row['ROUTE ID']])\n",
    "        originCity.append(inputData.loc[(inputData['ROUTE ID'] == row['ROUTE ID']) & (inputData['SEQ'] == seqList[-1])]['FROM CITY'].iloc[0])\n",
    "        originState.append(inputData.loc[(inputData['ROUTE ID'] == row['ROUTE ID']) & (inputData['SEQ'] == seqList[-1])]['FROM ST'].iloc[0])\n",
    "        originZip.append(inputData.loc[(inputData['ROUTE ID'] == row['ROUTE ID']) & (inputData['SEQ'] == seqList[-1])]['FROM ZIP'].iloc[0])\n",
    "\n",
    "    #Destiny city\n",
    "    destCity.append(row['TO CITY'])\n",
    "    destState.append(row['TO STATE'])\n",
    "    destZip.append(row['TO ZIP'])\n",
    "\n",
    "    #Earliest and Latest pickup dates\n",
    "    earliestDate, latestDate = dates(index)\n",
    "    earliestDateLs.append(earliestDate)\n",
    "    latestDateLs.append(latestDate)\n",
    "\n",
    "\n",
    "# Populating outputData\n",
    "outputData['LOAD ID'] = inputData['LOAD ID']\n",
    "outputData['ROUTE ID'] = inputData['ROUTE ID']\n",
    "outputData['FLOW TYPE'] = inputData['FLOW TYPE']\n",
    "outputData['LOAD WEIGHT'] = loadWeightLs\n",
    "outputData['LOAD MODE'] = loadModeLs\n",
    "outputData['PICKUP'] = pickup\n",
    "outputData['DROPOFF'] = dropoff\n",
    "outputData['ORIGIN CITY'] = originCity\n",
    "outputData['ORIGIN STATE'] = originState\n",
    "outputData['ORIGIN ZIP'] = originZip\n",
    "outputData['DEST CITY'] = destCity\n",
    "outputData['DEST STATE'] = destState\n",
    "outputData['DEST ZIP'] = destZip\n",
    "outputData['EARLIESTPICKTIME'] = earliestDateLs\n",
    "outputData['LATESTPICKTIME'] = latestDateLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0643dcb-198c-48d9-966c-1a2c06052fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOAD ID</th>\n",
       "      <th>LOAD MODE</th>\n",
       "      <th>ROUTE ID</th>\n",
       "      <th>FLOW TYPE</th>\n",
       "      <th>PICKUP</th>\n",
       "      <th>DROPOFF</th>\n",
       "      <th>ORIGIN CITY</th>\n",
       "      <th>ORIGIN STATE</th>\n",
       "      <th>ORIGIN ZIP</th>\n",
       "      <th>DEST CITY</th>\n",
       "      <th>DEST STATE</th>\n",
       "      <th>DEST ZIP</th>\n",
       "      <th>EARLIESTPICKTIME</th>\n",
       "      <th>LATESTPICKTIME</th>\n",
       "      <th>LOAD WEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90637</td>\n",
       "      <td>TL</td>\n",
       "      <td>F000570</td>\n",
       "      <td>Inbound</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Cedar Grove</td>\n",
       "      <td>WV</td>\n",
       "      <td>25039</td>\n",
       "      <td>Cedar Grove</td>\n",
       "      <td>WV</td>\n",
       "      <td>25039</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>33547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4769</td>\n",
       "      <td>LTL</td>\n",
       "      <td>F000570</td>\n",
       "      <td>Inbound</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Cedar Grove</td>\n",
       "      <td>WV</td>\n",
       "      <td>25039</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>PA</td>\n",
       "      <td>17109</td>\n",
       "      <td>2019-04-09</td>\n",
       "      <td>2019-04-09</td>\n",
       "      <td>5286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5310</td>\n",
       "      <td>LTL</td>\n",
       "      <td>F001155</td>\n",
       "      <td>Inbound</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Point Arena</td>\n",
       "      <td>CA</td>\n",
       "      <td>95468</td>\n",
       "      <td>Point Arena</td>\n",
       "      <td>CA</td>\n",
       "      <td>95468</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>15748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91180</td>\n",
       "      <td>TL</td>\n",
       "      <td>F001155</td>\n",
       "      <td>Inbound</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Point Arena</td>\n",
       "      <td>CA</td>\n",
       "      <td>95468</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>PA</td>\n",
       "      <td>17109</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>26531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116780</td>\n",
       "      <td>TL</td>\n",
       "      <td>F001722</td>\n",
       "      <td>Inbound</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Dewey</td>\n",
       "      <td>OK</td>\n",
       "      <td>74029</td>\n",
       "      <td>Dewey</td>\n",
       "      <td>OK</td>\n",
       "      <td>74029</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>28647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>181062</td>\n",
       "      <td>LTL</td>\n",
       "      <td>F143744</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Carlsbad</td>\n",
       "      <td>CA</td>\n",
       "      <td>92010</td>\n",
       "      <td>Grove</td>\n",
       "      <td>OK</td>\n",
       "      <td>74344</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>3503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>211343</td>\n",
       "      <td>LTL</td>\n",
       "      <td>F143875</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Carlsbad</td>\n",
       "      <td>CA</td>\n",
       "      <td>92010</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>OK</td>\n",
       "      <td>73173</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>2118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>210038</td>\n",
       "      <td>LTL</td>\n",
       "      <td>F143875</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Carlsbad</td>\n",
       "      <td>CA</td>\n",
       "      <td>92010</td>\n",
       "      <td>East Bernstadt</td>\n",
       "      <td>KY</td>\n",
       "      <td>40729</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>4163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>50306</td>\n",
       "      <td>TL</td>\n",
       "      <td>F143875</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>Carlsbad</td>\n",
       "      <td>CA</td>\n",
       "      <td>92010</td>\n",
       "      <td>Washington</td>\n",
       "      <td>VA</td>\n",
       "      <td>22747</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>37204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>180545</td>\n",
       "      <td>LTL</td>\n",
       "      <td>F143875</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Carlsbad</td>\n",
       "      <td>CA</td>\n",
       "      <td>92010</td>\n",
       "      <td>Cranberry Township</td>\n",
       "      <td>PA</td>\n",
       "      <td>16066</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1288 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LOAD ID LOAD MODE ROUTE ID FLOW TYPE  PICKUP  DROPOFF  ORIGIN CITY  \\\n",
       "0       90637        TL  F000570   Inbound       1        4  Cedar Grove   \n",
       "1        4769       LTL  F000570   Inbound       2        3  Cedar Grove   \n",
       "2        5310       LTL  F001155   Inbound       1        4  Point Arena   \n",
       "3       91180        TL  F001155   Inbound       2        3  Point Arena   \n",
       "4      116780        TL  F001722   Inbound       1        4        Dewey   \n",
       "...       ...       ...      ...       ...     ...      ...          ...   \n",
       "1283   181062       LTL  F143744  Outbound       1        6     Carlsbad   \n",
       "1284   211343       LTL  F143875  Outbound       4        5     Carlsbad   \n",
       "1285   210038       LTL  F143875  Outbound       3        6     Carlsbad   \n",
       "1286    50306        TL  F143875  Outbound       2        7     Carlsbad   \n",
       "1287   180545       LTL  F143875  Outbound       1        8     Carlsbad   \n",
       "\n",
       "     ORIGIN STATE  ORIGIN ZIP           DEST CITY DEST STATE  DEST ZIP  \\\n",
       "0              WV       25039         Cedar Grove         WV     25039   \n",
       "1              WV       25039          Harrisburg         PA     17109   \n",
       "2              CA       95468         Point Arena         CA     95468   \n",
       "3              CA       95468          Harrisburg         PA     17109   \n",
       "4              OK       74029               Dewey         OK     74029   \n",
       "...           ...         ...                 ...        ...       ...   \n",
       "1283           CA       92010               Grove         OK     74344   \n",
       "1284           CA       92010       Oklahoma City         OK     73173   \n",
       "1285           CA       92010      East Bernstadt         KY     40729   \n",
       "1286           CA       92010          Washington         VA     22747   \n",
       "1287           CA       92010  Cranberry Township         PA     16066   \n",
       "\n",
       "     EARLIESTPICKTIME LATESTPICKTIME  LOAD WEIGHT  \n",
       "0          2019-04-08     2019-04-08        33547  \n",
       "1          2019-04-09     2019-04-09         5286  \n",
       "2          2019-05-06     2019-05-07        15748  \n",
       "3          2019-05-07     2019-05-15        26531  \n",
       "4          2019-06-06     2019-06-06        28647  \n",
       "...               ...            ...          ...  \n",
       "1283       2019-09-20     2019-09-20         3503  \n",
       "1284       2019-09-27     2019-09-27         2118  \n",
       "1285       2019-09-27     2019-09-27         4163  \n",
       "1286       2019-09-27     2019-09-27        37204  \n",
       "1287       2019-09-27     2019-09-27          401  \n",
       "\n",
       "[1288 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b336f673-2b17-41c6-ade1-476a6d1109d1",
   "metadata": {},
   "source": [
    "#### Obtaining missing cities coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1bae713-203a-4805-a3f6-eaef2b22641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing city-state combinations:\n",
      "     ROUTE ID  SEQ  LOAD ID          FROM CITY FROM ST      TO CITY TO STATE\n",
      "0     F000570    1    90637            Rickman      TN  Cedar Grove       WV\n",
      "13    F004286    2     4918          Pall Mall      TN   Harrisburg       PA\n",
      "22    F007131    2     6356      Sugarloaf Key      FL    Asheville       NC\n",
      "30    F009044    2     5910               Totz      KY    Asheville       NC\n",
      "33    F010435    1    91312          Dover AFB      DE    Highfalls       NC\n",
      "...       ...  ...      ...                ...     ...          ...      ...\n",
      "1238  F140966    3    24883  Greenwell Springs      LA    Melbourne       FL\n",
      "1263  F142775    3   150750          Blakeslee      PA      Bayside       NY\n",
      "1264  F142775    4   209475            Bayside      NY  Bishopville       MD\n",
      "1268  F142900    4   212355           Redfield      NY     Westford       NY\n",
      "1283  F143744    3   181062            Meriden      WY        Grove       OK\n",
      "\n",
      "[178 rows x 7 columns]\n",
      "\n",
      "Unique missing city-state pairs:\n",
      "                   City State\n",
      "0               Rickman    TN\n",
      "13            Pall Mall    TN\n",
      "22        Sugarloaf Key    FL\n",
      "30                 Totz    KY\n",
      "33            Dover AFB    DE\n",
      "...                 ...   ...\n",
      "1231          Wiconisco    PA\n",
      "1238  Greenwell Springs    LA\n",
      "1264            Bayside    NY\n",
      "1268           Redfield    NY\n",
      "1283            Meriden    WY\n",
      "\n",
      "[161 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find missing by merge indicator\n",
    "input_cities = inputData.iloc[:, [6, 7]].rename(columns={'FROM CITY': 'City', 'FROM ST': 'State'})\n",
    "valid_cities = cities.iloc[:, [0, 1]].rename(columns={'city': 'City', 'state_id': 'State'})\n",
    "\n",
    "merged = input_cities.merge(\n",
    "    valid_cities.drop_duplicates(),  # Avoid duplicate matches\n",
    "    on=['City', 'State'],\n",
    "    how='left',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "mask = merged['_merge'] == 'left_only'\n",
    "rows_with_missing = inputData[mask]\n",
    "\n",
    "missing_combinations = merged.loc[mask, ['City', 'State']].drop_duplicates()\n",
    "\n",
    "print(\"Rows with missing city-state combinations:\")\n",
    "print(rows_with_missing.iloc[:,[0,1,4,6,7,9,10]])\n",
    "\n",
    "print(\"\\nUnique missing city-state pairs:\")\n",
    "print(missing_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35a5430d-8d9d-424e-8216-46996f34e054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edgar Tijerina\\AppData\\Local\\Temp\\ipykernel_1208\\2491546372.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  citiesNtCoor.append(app.geocode(f\"{row[0]} {row[1]}\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2"
     ]
    },
    {
     "ename": "GeocoderUnavailable",
     "evalue": "HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Pall+Mall+TN&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1301\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1302\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1303\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:538\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:369\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[1;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[1;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[0;32m    370\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:873\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    870\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    872\u001b[0m     )\n\u001b[1;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:873\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    870\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    872\u001b[0m     )\n\u001b[1;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Pall+Mall+TN&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\geopy\\adapters.py:482\u001b[0m, in \u001b[0;36mRequestsAdapter._request\u001b[1;34m(self, url, timeout, headers)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 482\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Pall+Mall+TN&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mGeocoderUnavailable\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(counter, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m citiesNtCoor\u001b[38;5;241m.\u001b[39mappend(\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeocode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     15\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1.1\u001b[39m) \u001b[38;5;66;03m# Mandatory 1s delay between requests\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py:297\u001b[0m, in \u001b[0;36mNominatim.geocode\u001b[1;34m(self, query, exactly_one, timeout, limit, addressdetails, language, geometry, extratags, country_codes, viewbox, bounded, featuretype, namedetails)\u001b[0m\n\u001b[0;32m    295\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.geocode: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, url)\n\u001b[0;32m    296\u001b[0m callback \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_json, exactly_one\u001b[38;5;241m=\u001b[39mexactly_one)\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_geocoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\geopy\\geocoders\\base.py:368\u001b[0m, in \u001b[0;36mGeocoder._call_geocoder\u001b[1;34m(self, url, callback, timeout, is_json, headers)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_json:\n\u001b[1;32m--> 368\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter\u001b[38;5;241m.\u001b[39mget_text(url, timeout\u001b[38;5;241m=\u001b[39mtimeout, headers\u001b[38;5;241m=\u001b[39mreq_headers)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\geopy\\adapters.py:472\u001b[0m, in \u001b[0;36mRequestsAdapter.get_json\u001b[1;34m(self, url, timeout, headers)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;241m*\u001b[39m, timeout, headers):\n\u001b[1;32m--> 472\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    474\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\geopy\\adapters.py:494\u001b[0m, in \u001b[0;36mRequestsAdapter._request\u001b[1;34m(self, url, timeout, headers)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GeocoderServiceError(message)\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 494\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GeocoderUnavailable(message)\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, requests\u001b[38;5;241m.\u001b[39mTimeout):\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GeocoderTimedOut(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mService timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mGeocoderUnavailable\u001b[0m: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Pall+Mall+TN&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Instatiate a new Nominatim client\n",
    "app = Nominatim(user_agent=\"MyApp\")\n",
    "import time\n",
    "\n",
    "citiesNtCoor = []\n",
    "\n",
    "# Query cities not found\n",
    "counter = 0\n",
    "for index, row in missing_combinations.iterrows():\n",
    "    counter += 1\n",
    "    print(counter, end='\\r')\n",
    "    citiesNtCoor.append(app.geocode(f\"{row[0]} {row[1]}\"))\n",
    "    time.sleep(1.1) # Mandatory 1s delay between requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a5642ad-625f-4c01-915e-83ba5cb8b978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaning cities not found:  {'city': [], 'state_id': []}\n"
     ]
    }
   ],
   "source": [
    "# Set new cities found\n",
    "foundCities = {'city':[], 'state_id':[], 'lat':[], 'lng':[]}\n",
    "citiesRemaning = {'city':[],'state_id':[]}\n",
    "for index, city in enumerate(citiesNtCoor):\n",
    "    try:\n",
    "        foundCities['lat'].append(city.latitude)\n",
    "        foundCities['lng'].append(city.longitude)    \n",
    "        foundCities['city'].append(missing_combinations.iloc[index,0])\n",
    "        foundCities['state_id'].append(missing_combinations.iloc[index,1])\n",
    "    except AttributeError:\n",
    "        citiesRemaning['city'].append(missing_combinations.iloc[index,0])\n",
    "        citiesRemaning['state_id'].append(missing_combinations.iloc[index,1])\n",
    "\n",
    "print('Remaning cities not found: ', citiesRemaning) \n",
    "\n",
    "# Update cities dataframe and drop duplicates\n",
    "fndCities = pd.DataFrame(foundCities)\n",
    "citiesFull = pd.concat([cities,fndCities], ignore_index = True)\n",
    "citiesFull.drop_duplicates(subset=['city','state_id'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a3e69-c379-42fc-a3d5-904f264d68d6",
   "metadata": {},
   "source": [
    "#### **Testing**\n",
    "To validate the data obtained some tests were developed. The tests consist of 3 randomly selected sample Routes compared to their manually solved counterparts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a166466e-ef97-425d-9f3f-73bd9461ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing samples\n",
    "sampleData = pd.read_excel(\n",
    "    'Uber Freight_Data Analytics_Assessment 2024.xlsx',\n",
    "    sheet_name='Example',\n",
    "    usecols=range(1,16),\n",
    "    header=0,\n",
    "    skiprows=39)\n",
    "\n",
    "# Importing sample trip distance\n",
    "sampleDist = pd.read_excel(\n",
    "    'Uber Freight_Data Analytics_Assessment 2024.xlsx',\n",
    "    sheet_name='Example',\n",
    "    usecols=[16],\n",
    "    header=0,\n",
    "    skiprows=39,\n",
    "    ).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f540019-8c11-4719-a9d5-d337543f424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = sampleData.iloc[0:3]\n",
    "sample2 = sampleData.iloc[3:7]\n",
    "sample3 = sampleData.iloc[7:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8d08776-ecf9-4be7-a4bf-7784772b1a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test1:\n",
      " OutputData:\n",
      "      LOAD ID LOAD MODE ROUTE ID FLOW TYPE  PICKUP  DROPOFF ORIGIN CITY  \\\n",
      "160    11751       LTL  F048342   Inbound       1        6      Exmore   \n",
      "161   110149        TL  F048342   Inbound       2        5        Knox   \n",
      "162    11232       LTL  F048342   Inbound       3        4    Bellview   \n",
      "\n",
      "    ORIGIN STATE  ORIGIN ZIP DEST CITY DEST STATE  DEST ZIP EARLIESTPICKTIME  \\\n",
      "160           VA       23350  Carlsbad         CA     92010       2019-01-08   \n",
      "161           PA       16232  Carlsbad         CA     92010       2019-01-09   \n",
      "162           IL       61604  Carlsbad         CA     92010       2019-01-11   \n",
      "\n",
      "    LATESTPICKTIME  LOAD WEIGHT  \n",
      "160     2019-01-09         6070  \n",
      "161     2019-01-09        25291  \n",
      "162     2019-01-11         3994   \n",
      "Sample:\n",
      "    LOAD ID LOAD MODE ROUTE ID FLOW TYPE  PICKUP  DROPOFF ORIGIN CITY  \\\n",
      "0    11751       LTL  F048342   Inbound       1        6      Exmore   \n",
      "1   110149        TL  F048342   Inbound       2        5        Knox   \n",
      "2    11232       LTL  F048342   Inbound       3        4    Bellview   \n",
      "\n",
      "  ORIGIN STATE  ORIGIN ZIP DEST CITY DEST STATE  DEST ZIP EARLIESTPICKTIME  \\\n",
      "0           VA       23350  Carlsbad         CA     92010       2019-01-08   \n",
      "1           PA       16232  Carlsbad         CA     92010       2019-01-09   \n",
      "2           IL       61604  Carlsbad         CA     92010       2019-01-11   \n",
      "\n",
      "  LATESTPICKTIME  LOAD WEIGHT  \n",
      "0     2019-01-08         6070  \n",
      "1     2019-01-10        25291  \n",
      "2     2019-01-12         3994  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest3\u001b[39m():\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest3:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutputData:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, outputData[outputData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROUTE ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m sample3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROUTE ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]],\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSample:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, sample3)\n\u001b[1;32m---> 32\u001b[0m \u001b[43mtest1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m test2()\n\u001b[0;32m     34\u001b[0m test3()\n",
      "Cell \u001b[1;32mIn[36], line 21\u001b[0m, in \u001b[0;36mtest1\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     fromCityData \u001b[38;5;241m=\u001b[39m citiesFull\u001b[38;5;241m.\u001b[39mloc[(citiesFull[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m fromCity) \u001b[38;5;241m&\u001b[39m (citiesFull[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m fromSt)]\n\u001b[0;32m     18\u001b[0m     toCityData \u001b[38;5;241m=\u001b[39m citiesFull\u001b[38;5;241m.\u001b[39mloc[(citiesFull[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m toCity) \u001b[38;5;241m&\u001b[39m (citiesFull[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m toSt)]\n\u001b[0;32m     20\u001b[0m     dists[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRIP DIST\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(geodesic((fromCityData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem(),fromCityData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlng\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()),\n\u001b[1;32m---> 21\u001b[0m                                (\u001b[43mtoCityData\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,toCityData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlng\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()))\u001b[38;5;241m.\u001b[39mmi)\n\u001b[0;32m     23\u001b[0m distsDf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(dists)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Sample Distances: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,sampleDist,\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimated Distances: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, distsDf,\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\base.py:418\u001b[0m, in \u001b[0;36mIndexOpsMixin.item\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m--> 418\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only convert an array of size 1 to a Python scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "#Checking for differences\n",
    "def test1():\n",
    "    index = inputData[inputData['ROUTE ID'] == sample1['ROUTE ID'].iloc[0]].index\n",
    "    \n",
    "    print('Test1:\\n', 'OutputData:\\n', outputData.iloc[index],'\\nSample:\\n', sample1)\n",
    "\n",
    "    # Trip time estimate\n",
    "    dists = {'TRIP DIST':[]}\n",
    "    sumDays = []\n",
    "    for i in index[:-1]:\n",
    "        \n",
    "        fromCity = inputData.iloc[i]['FROM CITY']\n",
    "        fromSt = inputData.iloc[i]['FROM ST']\n",
    "        toCity = inputData.iloc[i]['TO CITY']\n",
    "        toSt = inputData.iloc[i]['TO STATE']\n",
    "\n",
    "        fromCityData = citiesFull.loc[(citiesFull['city'] == fromCity) & (citiesFull['state_id'] == fromSt)]\n",
    "        toCityData = citiesFull.loc[(citiesFull['city'] == toCity) & (citiesFull['state_id'] == toSt)]\n",
    "    \n",
    "        dists['TRIP DIST'].append(geodesic((fromCityData['lat'].item(),fromCityData['lng'].item()),\n",
    "                                   (toCityData['lat'].item(),toCityData['lng'].item())).mi)\n",
    "    \n",
    "    distsDf = pd.DataFrame(dists)\n",
    "    print('\\n Sample Distances: \\n',sampleDist,'\\n', 'Estimated Distances: \\n', distsDf,'\\n')\n",
    "    \n",
    "def test2():\n",
    "    print('Test2:\\n', 'OutputData:\\n', outputData[outputData['ROUTE ID'] == sample2['ROUTE ID'].iloc[0]],'\\nSample:\\n', sample2)\n",
    "\n",
    "def test3():\n",
    "    print('Test3:\\n', 'OutputData:\\n', outputData[outputData['ROUTE ID'] == sample3['ROUTE ID'].iloc[0]],'\\nSample:\\n', sample3)\n",
    "\n",
    "test1()\n",
    "test2()\n",
    "test3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47baa8e-b00f-4464-81df-626ca96e30c7",
   "metadata": {},
   "source": [
    "**Test 1:**\n",
    "We can see that Origin City and Destiny city is incorrect and that our trip distance is inaccurate. corrections to the code is needed \n",
    "\n",
    "**Test 2 and Test 3:**\n",
    "Test 2 and 3 passed the test succesfully, no need for corrections needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f571816-6004-4aab-977d-cdafcf191a83",
   "metadata": {},
   "source": [
    "#### **Corrected code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65dff69b-0bfd-4815-a3c8-b0a1a2f482d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "from datetime import timedelta\n",
    "\n",
    "#Assuming LTL carriers cover 300mi/day\n",
    "AVGMILEAGE = 300\n",
    "\n",
    "\n",
    "def loadWeight(index):\n",
    "    \"\"\"\n",
    "    Calculates the load weight of each trip.\n",
    "\n",
    "    Uses index of input dataframe.\n",
    "    \"\"\"\n",
    "    route = inputData.loc[index]['ROUTE ID']\n",
    "    flow = inputData.loc[index]['FLOW TYPE']\n",
    "    seq = inputData.loc[index]['SEQ']\n",
    "    seqList = list(inputData['SEQ'].loc[inputData['ROUTE ID'] == route])\n",
    "\n",
    "\n",
    "    if flow == 'Outbound':\n",
    "        if seq == len(seqList):\n",
    "            return inputData.loc[index]['LEG WEIGHT']\n",
    "        nextWeight = inputData.loc[(inputData['ROUTE ID'] == route ) & (inputData['SEQ'] == seq + 1)]['LEG WEIGHT']\n",
    "        nextWeight = nextWeight.iloc[0]\n",
    "\n",
    "        return inputData.loc[index]['LEG WEIGHT'] - nextWeight\n",
    "        \n",
    "    else:\n",
    "        if seq == 1:\n",
    "            return inputData.loc[index]['LEG WEIGHT']\n",
    "        prevWeight = inputData.loc[(inputData['ROUTE ID'] == route ) & (inputData['SEQ'] == seq - 1)]['LEG WEIGHT']\n",
    "        prevWeight = prevWeight.iloc[0]\n",
    "\n",
    "        return inputData.loc[index]['LEG WEIGHT'] - prevWeight\n",
    "\n",
    "def pickDrop(index):\n",
    "    \"\"\"\n",
    "    Determines de pickup and dropoff of each trip.\n",
    "    \"\"\"\n",
    "    route = inputData.loc[index]['ROUTE ID']\n",
    "    flow = inputData.loc[index]['FLOW TYPE']\n",
    "    seq = inputData.loc[index]['SEQ']\n",
    "    seqList = list(inputData['SEQ'].loc[inputData['ROUTE ID'] == route])\n",
    "    seqList.sort()\n",
    "\n",
    "    if flow == 'Outbound':\n",
    "        pickup = seqList[len(seqList) - seq]\n",
    "        dropoff = seq + max(seqList)\n",
    "    else:\n",
    "        pickup = seq\n",
    "        dropoff = seqList[len(seqList) - seq] + max(seqList)\n",
    "\n",
    "    return pickup, dropoff\n",
    "\n",
    "    \n",
    "\n",
    "def dates(index):\n",
    "    \"\"\"\n",
    "    Determines and calculates the earliest and latest pickup dates.\n",
    "    Uses geodesic calculations to determine a rough estimate distance for each stop,\n",
    "    \n",
    "    In Inbound routes the earliest pickup depends on the supplier, \n",
    "    and the latest on the calculated time of arrival\n",
    "\n",
    "    In Outbound routes the earliest and latest pickup depends on the last load in the sequence.\n",
    "    \"\"\"\n",
    "    route = inputData.loc[index]['ROUTE ID']\n",
    "    flow = inputData.loc[index]['FLOW TYPE']\n",
    "    seq = inputData.loc[index]['SEQ']\n",
    "    seqList = list(inputData['SEQ'].loc[inputData['ROUTE ID'] == route])\n",
    "    seqList.sort()\n",
    "\n",
    "    if flow == 'Outbound':\n",
    "        eDate = inputData.loc[(inputData['ROUTE ID'] == route ) & (inputData['SEQ'] == seqList[-1])]['DATE'].iloc[0]\n",
    "        lDate = eDate\n",
    "\n",
    "        return eDate, lDate\n",
    "    else:\n",
    "        eDate = inputData.loc[(inputData['ROUTE ID'] == route ) & (inputData['SEQ'] == seq)]['DATE'].iloc[0]\n",
    "        \n",
    "        fromCity = inputData.iloc[index]['FROM CITY']\n",
    "        fromSt = inputData.iloc[index]['FROM ST']\n",
    "        toCity = inputData.iloc[index]['TO CITY']\n",
    "        toSt = inputData.iloc[index]['TO STATE']\n",
    "\n",
    "        # Checks that the origin and destination cities exists whitin the data base to perform the calculations\n",
    "        check1 = cities[(cities['city'] == fromCity) & (cities['state_id'] == fromSt)].any()\n",
    "        check2 = cities[(cities['city'] == toCity) & (cities['state_id'] == toSt)].any()\n",
    "\n",
    "        \n",
    "        if check1.any() and check2.any():\n",
    "            fromCityData = cities.loc[(cities['city'] == fromCity) & (cities['state_id'] == fromSt)]\n",
    "            toCityData = cities.loc[(cities['city'] == toCity) & (cities['state_id'] == toSt)]\n",
    "\n",
    "            \n",
    "            # Geodesic calculation since it takes into account earth curvature\n",
    "            estDist = geodesic((fromCityData['lat'].item(),fromCityData['lng'].item()),\n",
    "                               (toCityData['lat'].item(),toCityData['lng'].item())).mi\n",
    "                \n",
    "            sumDays = int(estDist // AVGMILEAGE)\n",
    "\n",
    "            lDate = eDate + timedelta(days=sumDays)\n",
    "            \n",
    "            return eDate, lDate\n",
    "\n",
    "        #If the cities wheren't found, it defaults into the original earliest Pickup\n",
    "        lDate = eDate\n",
    "\n",
    "        # Storing cities not found\n",
    "        if check1.any():\n",
    "            citiesNt.append((fromCity,fromSt))\n",
    "        if check2.any():\n",
    "            citiesNt.append((toCity,toSt))\n",
    "        \n",
    "        return eDate, lDate\n",
    "        \n",
    "# Lists initialization\n",
    "# whole List assigments are faster than dataframe row iterations\n",
    "loadWeightLs = []\n",
    "loadModeLs = []\n",
    "pickup = []\n",
    "dropoff = []\n",
    "originCity = []\n",
    "originState = []\n",
    "originZip = []\n",
    "destCity = []\n",
    "destState = []\n",
    "destZip = []\n",
    "earliestDateLs = []\n",
    "latestDateLs = []\n",
    "\n",
    "#Cities not found\n",
    "citiesNt = []\n",
    "\n",
    "for index, row in inputData.iterrows():\n",
    "\n",
    "    #Load weight\n",
    "    loadWeightLs.append(loadWeight(index))\n",
    "\n",
    "    # Loadmode\n",
    "    if loadWeightLs[index] > 20000:\n",
    "        loadModeLs.append('TL')\n",
    "    else:\n",
    "        loadModeLs.append('LTL')\n",
    "\n",
    "    #Pick and Drop sequence\n",
    "    pick, drop = pickDrop(index)\n",
    "    pickup.append(pick)\n",
    "    dropoff.append(drop)\n",
    "\n",
    "    # Origin city and Destiny city\n",
    "    if row['FLOW TYPE'] == 'Outbound':\n",
    "\n",
    "        # Origin city is the last city where the package is shipped off\n",
    "        originCity.append(inputData.loc[(inputData['ROUTE ID'] == row['ROUTE ID']) & (inputData['SEQ'] == 1)]['FROM CITY'].iloc[0])\n",
    "        originState.append(inputData.loc[(inputData['ROUTE ID'] == row['ROUTE ID']) & (inputData['SEQ'] == 1)]['FROM ST'].iloc[0])\n",
    "        originZip.append(inputData.loc[(inputData['ROUTE ID'] == row['ROUTE ID']) & (inputData['SEQ'] == 1)]['FROM ZIP'].iloc[0])\n",
    "        \n",
    "        # Destiny city is where the package is droped off\n",
    "        destCity.append(row['TO CITY'])\n",
    "        destState.append(row['TO STATE'])\n",
    "        destZip.append(row['TO ZIP'])\n",
    "    \n",
    "    else:\n",
    "        # Inbound route\n",
    "        seqList = list(inputData['SEQ'].loc[inputData['ROUTE ID'] == row['ROUTE ID']])\n",
    "        \n",
    "        # Destiny city is the last city in the trip\n",
    "        destCity.append(inputData.loc[(inputData['ROUTE ID'] == row['ROUTE ID']) & (inputData['SEQ'] == len(seqList))]['TO CITY'].iloc[0])\n",
    "        destState.append(inputData.loc[(inputData['ROUTE ID'] == row['ROUTE ID']) & (inputData['SEQ'] == len(seqList))]['TO STATE'].iloc[0])\n",
    "        destZip.append(inputData.loc[(inputData['ROUTE ID'] == row['ROUTE ID']) & (inputData['SEQ'] == len(seqList))]['TO ZIP'].iloc[0])\n",
    "        \n",
    "        # Origin city is the city where the load is picked up\n",
    "        originCity.append(row['FROM CITY'])\n",
    "        originState.append(row['FROM ST'])\n",
    "        originZip.append(row['FROM ZIP'])\n",
    "\n",
    "    #Earliest and Latest pickup dates\n",
    "    earliestDate, latestDate = dates(index)\n",
    "    earliestDateLs.append(earliestDate)\n",
    "    latestDateLs.append(latestDate)\n",
    "\n",
    "\n",
    "# Populating outputData\n",
    "outputData['LOAD ID'] = inputData['LOAD ID']\n",
    "outputData['ROUTE ID'] = inputData['ROUTE ID']\n",
    "outputData['FLOW TYPE'] = inputData['FLOW TYPE']\n",
    "outputData['LOAD WEIGHT'] = loadWeightLs\n",
    "outputData['LOAD MODE'] = loadModeLs\n",
    "outputData['PICKUP'] = pickup\n",
    "outputData['DROPOFF'] = dropoff\n",
    "outputData['ORIGIN CITY'] = originCity\n",
    "outputData['ORIGIN STATE'] = originState\n",
    "outputData['ORIGIN ZIP'] = originZip\n",
    "outputData['DEST CITY'] = destCity\n",
    "outputData['DEST STATE'] = destState\n",
    "outputData['DEST ZIP'] = destZip\n",
    "outputData['EARLIESTPICKTIME'] = earliestDateLs\n",
    "outputData['LATESTPICKTIME'] = latestDateLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19c47b20-f7d2-4eac-bd40-259a0053237b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test1:\n",
      " OutputData:\n",
      "      LOAD ID LOAD MODE ROUTE ID FLOW TYPE  PICKUP  DROPOFF ORIGIN CITY  \\\n",
      "160    11751       LTL  F048342   Inbound       1        6      Exmore   \n",
      "161   110149        TL  F048342   Inbound       2        5        Knox   \n",
      "162    11232       LTL  F048342   Inbound       3        4    Bellview   \n",
      "\n",
      "    ORIGIN STATE  ORIGIN ZIP DEST CITY DEST STATE  DEST ZIP EARLIESTPICKTIME  \\\n",
      "160           VA       23350  Carlsbad         CA     92010       2019-01-08   \n",
      "161           PA       16232  Carlsbad         CA     92010       2019-01-09   \n",
      "162           IL       61604  Carlsbad         CA     92010       2019-01-11   \n",
      "\n",
      "    LATESTPICKTIME  LOAD WEIGHT  \n",
      "160     2019-01-09         6070  \n",
      "161     2019-01-09        25291  \n",
      "162     2019-01-11         3994   \n",
      "Sample:\n",
      "    LOAD ID LOAD MODE ROUTE ID FLOW TYPE  PICKUP  DROPOFF ORIGIN CITY  \\\n",
      "0    11751       LTL  F048342   Inbound       1        6      Exmore   \n",
      "1   110149        TL  F048342   Inbound       2        5        Knox   \n",
      "2    11232       LTL  F048342   Inbound       3        4    Bellview   \n",
      "\n",
      "  ORIGIN STATE  ORIGIN ZIP DEST CITY DEST STATE  DEST ZIP EARLIESTPICKTIME  \\\n",
      "0           VA       23350  Carlsbad         CA     92010       2019-01-08   \n",
      "1           PA       16232  Carlsbad         CA     92010       2019-01-09   \n",
      "2           IL       61604  Carlsbad         CA     92010       2019-01-11   \n",
      "\n",
      "  LATESTPICKTIME  LOAD WEIGHT  \n",
      "0     2019-01-08         6070  \n",
      "1     2019-01-10        25291  \n",
      "2     2019-01-12         3994  \n",
      "\n",
      " Sample Distances: \n",
      "    TRIP DIST\n",
      "0      467.0\n",
      "1      712.0 \n",
      " Estimated Distances: \n",
      "    TRIP DIST\n",
      "0  323.55247 \n",
      "\n",
      "Trip distance accuracy: -45 %\n",
      "\n",
      "Test2:\n",
      " OutputData:\n",
      "      LOAD ID LOAD MODE ROUTE ID FLOW TYPE  PICKUP  DROPOFF ORIGIN CITY  \\\n",
      "229   154280       LTL  F057475  Outbound       4        5  Harrisburg   \n",
      "230   183773       LTL  F057475  Outbound       3        6  Harrisburg   \n",
      "231   155063       LTL  F057475  Outbound       2        7  Harrisburg   \n",
      "232    51446        TL  F057475  Outbound       1        8  Harrisburg   \n",
      "\n",
      "    ORIGIN STATE  ORIGIN ZIP     DEST CITY DEST STATE  DEST ZIP  \\\n",
      "229           PA       17109    Cedar Hill         MO     63016   \n",
      "230           PA       17109       Cordova         NM     87523   \n",
      "231           PA       17109         Heber         CA     92249   \n",
      "232           PA       17109  Grover Beach         CA     93483   \n",
      "\n",
      "    EARLIESTPICKTIME LATESTPICKTIME  LOAD WEIGHT  \n",
      "229       2019-02-08     2019-02-08          172  \n",
      "230       2019-02-08     2019-02-08          183  \n",
      "231       2019-02-08     2019-02-08         4289  \n",
      "232       2019-02-08     2019-02-08        38344   \n",
      "Sample:\n",
      "    LOAD ID LOAD MODE ROUTE ID FLOW TYPE  PICKUP  DROPOFF ORIGIN CITY  \\\n",
      "3   154280       LTL  F057475  Outbound       4        5  Harrisburg   \n",
      "4   183773       LTL  F057475  Outbound       3        6  Harrisburg   \n",
      "5   155063       LTL  F057475  Outbound       2        7  Harrisburg   \n",
      "6    51446        TL  F057475  Outbound       1        8  Harrisburg   \n",
      "\n",
      "  ORIGIN STATE  ORIGIN ZIP     DEST CITY DEST STATE  DEST ZIP  \\\n",
      "3           PA       17109    Cedar Hill         MO     63016   \n",
      "4           PA       17109       Cordova         NM     87523   \n",
      "5           PA       17109         Heber         CA     92249   \n",
      "6           PA       17109  Grover Beach         CA     93483   \n",
      "\n",
      "  EARLIESTPICKTIME LATESTPICKTIME  LOAD WEIGHT  \n",
      "3       2019-02-08     2019-02-08          172  \n",
      "4       2019-02-08     2019-02-08          183  \n",
      "5       2019-02-08     2019-02-08         4289  \n",
      "6       2019-02-08     2019-02-08        38344  \n",
      "Test3:\n",
      " OutputData:\n",
      "      LOAD ID LOAD MODE ROUTE ID FLOW TYPE  PICKUP  DROPOFF ORIGIN CITY  \\\n",
      "875    21899       LTL  F115254  Outbound       2        3       Tyler   \n",
      "876    35471       LTL  F115254  Outbound       1        4       Tyler   \n",
      "\n",
      "    ORIGIN STATE  ORIGIN ZIP     DEST CITY DEST STATE  DEST ZIP  \\\n",
      "875           TX       75706         Klein         TX     77389   \n",
      "876           TX       75706  Lake Charles         LA     70607   \n",
      "\n",
      "    EARLIESTPICKTIME LATESTPICKTIME  LOAD WEIGHT  \n",
      "875       2019-11-26     2019-11-26        16327  \n",
      "876       2019-11-26     2019-11-26        18782   \n",
      "Sample:\n",
      "    LOAD ID LOAD MODE ROUTE ID FLOW TYPE  PICKUP  DROPOFF ORIGIN CITY  \\\n",
      "7    21899       LTL  F115254  Outbound       2        3       Tyler   \n",
      "8    35471       LTL  F115254  Outbound       1        4       Tyler   \n",
      "\n",
      "  ORIGIN STATE  ORIGIN ZIP     DEST CITY DEST STATE  DEST ZIP  \\\n",
      "7           TX       75706         Klein         TX     77389   \n",
      "8           TX       75707  Lake Charles         LA     70607   \n",
      "\n",
      "  EARLIESTPICKTIME LATESTPICKTIME  LOAD WEIGHT  \n",
      "7       2019-11-26     2019-11-26        16327  \n",
      "8       2019-11-26     2019-11-26        18782  \n",
      "\n",
      "Cities not found: 48\n"
     ]
    }
   ],
   "source": [
    "#Checking for differences\n",
    "def test1():\n",
    "    index = inputData[inputData['ROUTE ID'] == sample1['ROUTE ID'].iloc[0]].index\n",
    "    \n",
    "    print('Test1:\\n', 'OutputData:\\n', outputData.iloc[index],'\\nSample:\\n', sample1)\n",
    "\n",
    "    # Trip time estimate\n",
    "    dists = {'TRIP DIST':[]}\n",
    "    sumDays = []\n",
    "    \n",
    "    # If the cities missing weren't searched, it might fail to test the last distance. Adjust index[:-1], index[:1]\n",
    "    for i in index[:1]:\n",
    "        \n",
    "        fromCity = inputData.iloc[i]['FROM CITY']\n",
    "        fromSt = inputData.iloc[i]['FROM ST']\n",
    "        toCity = inputData.iloc[i]['TO CITY']\n",
    "        toSt = inputData.iloc[i]['TO STATE']\n",
    "\n",
    "        fromCityData = citiesFull.loc[(citiesFull['city'] == fromCity) & (citiesFull['state_id'] == fromSt)]\n",
    "        toCityData = citiesFull.loc[(citiesFull['city'] == toCity) & (citiesFull['state_id'] == toSt)]\n",
    "\n",
    "        from_lat = fromCityData['lat'].iloc[0]\n",
    "        from_lng = fromCityData['lng'].iloc[0]\n",
    "        to_lat = toCityData['lat'].iloc[0]\n",
    "        to_lng = toCityData['lng'].iloc[0]\n",
    "\n",
    "        dists['TRIP DIST'].append(geodesic((from_lat, from_lng),\n",
    "                                   (to_lat, to_lng)).mi)\n",
    "    \n",
    "    distsDf = pd.DataFrame(dists)\n",
    "    print('\\n Sample Distances: \\n',sampleDist,'\\n', 'Estimated Distances: \\n', distsDf,'\\n')\n",
    "    accu = round(((distsDf.mean()/sampleDist.mean())*100).item() - 100)\n",
    "    print('Trip distance accuracy:', accu,'%\\n')\n",
    "    \n",
    "def test2():\n",
    "    print('Test2:\\n', 'OutputData:\\n', outputData[outputData['ROUTE ID'] == sample2['ROUTE ID'].iloc[0]],'\\nSample:\\n', sample2)\n",
    "\n",
    "def test3():\n",
    "    print('Test3:\\n', 'OutputData:\\n', outputData[outputData['ROUTE ID'] == sample3['ROUTE ID'].iloc[0]],'\\nSample:\\n', sample3)\n",
    "\n",
    "test1()\n",
    "test2()\n",
    "test3()\n",
    "\n",
    "print('\\nCities not found:', len(citiesNt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6404f5-9ad5-418d-8f58-40c20067b015",
   "metadata": {},
   "source": [
    "### **Results**\n",
    "\n",
    "With the code corrected the output now has the proper format, with the caveat that the latest pickup date for inbound routes is underestimated due to the limitation of being only geodesic calculations and not taking into account real USA routes. This could be improved in the future with better data or tweaks to the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9f2b1-da4e-4fae-8402-8ab14cafd6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputData.to_csv('outputData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee50ce-a343-45b8-b7da-ca0b0f77bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
